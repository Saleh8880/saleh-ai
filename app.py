import streamlit as st
import requests

st.set_page_config(page_title="SALEH AI PRO", page_icon="ğŸ‘‘")

NEW_API_KEY = "AIzaSyAap0wkUBLjvHgmKe4sfil8FWgoc3Tfp5M"

st.title("ğŸ‘‘ SALEH AI - ULTIMATE")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
for message in st.session_state.messages:
    with st.chat_message(message["role"]): st.markdown(message["content"])

# Ø¯Ø§Ù„Ø© Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø´ØºØ§Ù„ ÙØ¹Ù„ÙŠØ§Ù‹ ÙÙŠ Ø­Ø³Ø§Ø¨Ùƒ
def find_any_working_model():
    # Ø¨Ù†Ø³Ø£Ù„ Ø¬ÙˆØ¬Ù„ Ø¹Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ùƒ
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={NEW_API_KEY}"
    try:
        response = requests.get(url)
        models_data = response.json()
        # Ø¨Ù†ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù…ÙˆØ¯ÙŠÙ„ Ø¨ÙŠØ¯Ø¹Ù… generateContent
        for m in models_data.get('models', []):
            if 'generateContent' in m.get('supportedGenerationMethods', []):
                return m['name'] # Ù‡ÙŠØ±Ø¬Ø¹ Ø­Ø§Ø¬Ø© Ø²ÙŠ models/gemini-1.5-flash-latest
        return "models/gemini-pro" # Ø§Ø­ØªÙŠØ§Ø·ÙŠ
    except:
        return "models/gemini-pro"

if prompt := st.chat_input("Ø§Ø³Ø£Ù„ ØµØ§Ù„Ø­ AI..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)

    with st.chat_message("assistant"):
        working_model = find_any_working_model()
        # Ù†Ø¯Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù„ÙŠ Ù„Ù‚ÙŠÙ†Ø§Ù‡ Ø´ØºØ§Ù„
        url = f"https://generativelanguage.googleapis.com/v1beta/{working_model}:generateContent?key={NEW_API_KEY}"
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        
        try:
            res = requests.post(url, json=payload)
            data = res.json()
            if res.status_code == 200:
                ans = data['candidates'][0]['content']['parts'][0]['text']
                st.markdown(ans)
                st.session_state.messages.append({"role": "assistant", "content": ans})
            else:
                st.error(f"Ø¬ÙˆØ¬Ù„ Ù„Ø³Ù‡ Ù…Ø¹Ø§Ù†Ø¯Ø©! Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù„ÙŠ Ù„Ù‚ÙŠÙ†Ø§Ù‡ Ù‡Ùˆ {working_model} Ø¨Ø³ Ù…Ø´ Ø±Ø§Ø¶ÙŠ ÙŠØ±Ø¯.")
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
