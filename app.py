import streamlit as st
import requests

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ø¬Ù…Ø§Ù„ÙŠØ§Øª (Ø§Ù„Ø³ØªØ§ÙŠÙ„)
st.set_page_config(page_title="SALEH AI GOLD", page_icon="ğŸ‘‘", layout="centered")

st.markdown("""
    <style>
    /* Ø®Ù„ÙÙŠØ© Ø§Ù„ØµÙØ­Ø© */
    .stApp { background: linear-gradient(to bottom, #0f0f0f, #000000); }
    
    /* Ø´ÙƒÙ„ ÙÙ‚Ø§Ø¹Ø§Øª Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© */
    div[data-testid="stChatMessage"] {
        border-radius: 20px;
        padding: 15px;
        margin-bottom: 10px;
        border: 1px solid #D4AF37; /* Ø¥Ø·Ø§Ø± Ø°Ù‡Ø¨ÙŠ Ø®ÙÙŠÙ */
        background-color: #1a1a1a !important;
        box-shadow: 0 4px 15px rgba(0,0,0,0.5);
    }
    
    /* ØªÙ…ÙŠÙŠØ² Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… */
    div[data-testid="stChatMessageUser"] {
        border-right: 5px solid #D4AF37 !important;
        background-color: #262626 !important;
    }

    /* ØªÙ…ÙŠÙŠØ² Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ */
    div[data-testid="stChatMessageAssistant"] {
        border-left: 5px solid #ffffff !important;
    }

    /* ØªØºÙŠÙŠØ± Ø´ÙƒÙ„ Ø®Ø· Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† */
    h1 {
        color: #D4AF37;
        text-shadow: 0px 0px 10px rgba(212, 175, 55, 0.5);
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        text-align: center;
    }

    /* Ø¥Ø®ÙØ§Ø¡ Ø¹Ù„Ø§Ù…Ø§Øª Ø³ØªØ±ÙŠÙ… Ù„ÙŠØª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ‘‘ SALEH AI PRO")
st.markdown("<p style='text-align: center; color: #888;'>Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø´Ø®ØµÙŠ Ø§Ù„Ø°ÙƒÙŠ - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ©</p>", unsafe_allow_html=True)

# 2. Ø§Ù„Ù…Ø­Ø±Ùƒ (Ù†ÙØ³ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù„ÙŠ Ø§Ø´ØªØºÙ„ Ù…Ø¹Ø§Ùƒ Ø¨Ø§Ù„Ø¸Ø¨Ø·)
NEW_API_KEY = "AIzaSyAap0wkUBLjvHgmKe4sfil8FWgoc3Tfp5M"

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

def find_any_working_model():
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={NEW_API_KEY}"
    try:
        response = requests.get(url)
        models_data = response.json()
        for m in models_data.get('models', []):
            if 'generateContent' in m.get('supportedGenerationMethods', []):
                return m['name']
        return "models/gemini-1.5-flash"
    except:
        return "models/gemini-1.5-flash"

if prompt := st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ ØµØ§Ù„Ø­..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("ØµØ§Ù„Ø­ AI ÙŠÙƒØªØ¨ Ø§Ù„Ø¢Ù†..."):
            working_model = find_any_working_model()
            url = f"https://generativelanguage.googleapis.com/v1beta/{working_model}:generateContent?key={NEW_API_KEY}"
            payload = {"contents": [{"parts": [{"text": prompt}]}]}
            
            try:
                res = requests.post(url, json=payload)
                data = res.json()
                if res.status_code == 200:
                    ans = data['candidates'][0]['content']['parts'][0]['text']
                    st.markdown(ans)
                    st.session_state.messages.append({"role": "assistant", "content": ans})
                else:
                    st.error("Ø¬ÙˆØ¬Ù„ Ù…Ø´ØºÙˆÙ„Ø© Ø´ÙˆÙŠØ©ØŒ Ø­Ø§ÙˆÙ„ ÙƒÙ…Ø§Ù† Ø«ÙˆØ§Ù†ÙŠ.")
            except:
                st.error("Ø­Ø¯Ø« Ø®Ø·Ø£ Ø¨Ø³ÙŠØ· ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„.")
