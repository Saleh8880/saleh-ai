import streamlit as st
import google.generativeai as genai

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.set_page_config(page_title="SALEH AI PRO", page_icon="ğŸ‘‘", layout="centered")

# Ø³ØªØ§ÙŠÙ„ CSS Ù…ØªØ·ÙˆØ±
st.markdown("""
    <style>
    .main { background-color: #050505; }
    .stChatMessage { border-radius: 20px; margin-bottom: 10px; border: 1px solid #333; }
    .stChatMessage[data-testid="stChatMessageUser"] { background-color: #1a1a1a; border-color: #D4AF37; }
    .stChatMessage[data-testid="stChatMessageAssistant"] { background-color: #0d0d0d; border-color: #444; }
    .stChatInputContainer { padding-bottom: 20px; }
    h1 { color: #D4AF37; text-align: center; font-family: 'Cairo', sans-serif; text-shadow: 2px 2px 4px #000; }
    .stButton>button { width: 100%; border-radius: 20px; background-color: #D4AF37; color: black; font-weight: bold; border: none; }
    .stButton>button:hover { background-color: #b8962e; color: white; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ‘‘ SALEH AI - PRO")

# 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ API
API_KEY = "AIzaSyA83bkpXNvLB7bmcqOpDi7ucGYqI7K7kD4"
genai.configure(api_key=API_KEY)

# ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
@st.cache_resource
def get_model():
    try:
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        for m in models:
            if 'gemini-1.5-flash' in m: return m
        return models[0]
    except: return 'gemini-1.5-flash'

model = genai.GenerativeModel(get_model())

# 3. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Session State)
if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø²Ø± Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©
with st.sidebar:
    st.header("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()
    st.markdown("---")
    st.write("Ø¥ØµØ¯Ø§Ø±: 2.0 (Gold Edition)")
    st.write("Ø§Ù„Ù…Ø·ÙˆØ±: ØµØ§Ù„Ø­")

# 4. Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ ÙˆØ§Ù„Ø±Ø¯
if prompt := st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ Ø°ÙƒØ§Ø¡ ØµØ§Ù„Ø­..."):
    # Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Ø±Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
            try:
                # Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø®ÙÙŠØ© Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù„ÙŠÙƒÙˆÙ† Ù…Ø³Ø§Ø¹Ø¯ ØµØ§Ù„Ø­
                full_prompt = f"Ø£Ù†Øª Ø§Ù„Ø¢Ù† SALEH AIØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙˆØ´Ø®ØµÙŠ Ù„ØµØ§Ù„Ø­. Ø±Ø¯ Ø¹Ù„ÙŠÙ‡ Ø¨Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙˆÙˆØ¯. Ø§Ù„Ø³Ø¤Ø§Ù„ Ù‡Ùˆ: {prompt}"
                response = model.generate_content(full_prompt)
                
                if response.text:
                    st.markdown(response.text)
                    st.session_state.messages.append({"role": "assistant", "content": response.text})
                else:
                    st.error("Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø¯.")
            except Exception as e:
                st.error(f"Ø®Ø·Ø£: {e}")
