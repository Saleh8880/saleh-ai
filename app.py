import streamlit as st
import requests

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„ØªØµÙ…ÙŠÙ… (Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ù„ÙŠ Ø·Ù„Ø¨ØªÙ‡) ---
st.set_page_config(page_title="SALEH AI PRO", page_icon="ğŸ‘‘")

st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;700&display=swap');
    html, body, [class*="css"] { font-family: 'Cairo', sans-serif; }
    .stApp { background-color: #0e1117; }
    h1 { color: #FFD700 !important; text-align: center; border-bottom: 1px solid #333; padding-bottom: 20px; }
    .stChatMessage { background-color: #262730; border-radius: 10px; margin-bottom: 10px; }
    .stTextInput > div > div > input { background-color: #1E1E1E; color: white; border-radius: 20px; }
</style>
""", unsafe_allow_html=True)

NEW_API_KEY = "AIzaSyAap0wkUBLjvHgmKe4sfil8FWgoc3Tfp5M"

st.title("ğŸ‘‘ SALEH AI - ULTIMATE")

if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 2. Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ---
for message in st.session_state.messages:
    avatar = "ğŸ‘‘" if message["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

# --- 3. Ø¯Ø§Ù„Ø© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ù…Ø¹ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¨Ø³ÙŠØ· Ù„ØªÙØ§Ø¯ÙŠ Ø§Ù„Ø®Ø·Ø£) ---
def find_any_working_model():
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={NEW_API_KEY}"
    try:
        response = requests.get(url)
        models_data = response.json()
        
        for m in models_data.get('models', []):
            # --- Ø§Ù„Ø³Ø·Ø± Ø¯Ù‡ Ù‡Ùˆ Ø§Ù„Ù„ÙŠ Ø¨ÙŠØ­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ---
            # Ø¨Ù†Ù‚ÙˆÙ„Ù‡ Ù„Ùˆ Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠÙ‡ "2.5" ÙÙƒÙƒ Ù…Ù†Ù‡ ÙˆØ´ÙˆÙ Ø§Ù„Ù„ÙŠ Ø¨Ø¹Ø¯Ù‡
            if '2.5' in m['name']:
                continue 
            # ------------------------------------
            
            if 'generateContent' in m.get('supportedGenerationMethods', []):
                return m['name']
        
        return "models/gemini-pro"
    except:
        return "models/gemini-pro"

# --- 4. Ø§Ù„ØªØ´ØºÙŠÙ„ ---
if prompt := st.chat_input("Ø§Ø³Ø£Ù„ ØµØ§Ù„Ø­ AI..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ‘¤"): st.markdown(prompt)

    with st.chat_message("assistant", avatar="ğŸ‘‘"):
        try:
            working_model = find_any_working_model()
            
            url = f"https://generativelanguage.googleapis.com/v1beta/{working_model}:generateContent?key={NEW_API_KEY}"
            payload = {"contents": [{"parts": [{"text": prompt}]}]}
            
            res = requests.post(url, json=payload)
            data = res.json()
            
            if res.status_code == 200:
                ans = data['candidates'][0]['content']['parts'][0]['text']
                st.markdown(ans)
                st.session_state.messages.append({"role": "assistant", "content": ans})
            else:
                st.error(f"Ø®Ø·Ø£: Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ {working_model} Ø±ÙØ¶ Ø§Ù„Ø±Ø¯ (Code: {res.status_code})")
        
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
